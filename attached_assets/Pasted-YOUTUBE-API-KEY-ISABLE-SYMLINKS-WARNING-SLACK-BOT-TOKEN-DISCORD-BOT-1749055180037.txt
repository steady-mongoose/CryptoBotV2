YOUTUBE_API_KEY
••••••••
ISABLE_SYMLINKS_WARNING
••••••••
SLACK_BOT_TOKEN
••••••••
DISCORD_BOT_TOKEN
••••••••
DISCORD_TOKEN
••••••••
DISCORD_CHANNEL_ID
••••••••
NEWSAPI_KEY
••••••••
DAPPRADAR_API_KEY
••••••••
COINMARKETCAP_API_KEY
••••••••
CRYPTOCOMPARE_API_KEY
••••••••
LUNARCRUSH_API_KEY
••••••••
DISCORD_WEBHOOK_URL
••••••••
X_CONSUMER_KEY
••••••••
X_CONSUMER_SECRET
••••••••
X_ACCESS_TOKEN
••••••••
X_ACCESS_TOKEN_SECRET
••••••••
BEARER_TOKEN
••••••••
X_CLIENT_ID
••••••••
X_CLIENT_SECRET
••••••••
BINANCE_US_API_KEY
••••••••
BINANCE_US_API_SECRET
••••••••
COINBASE_API_KEY
••••••••
COINBASE_API_SECRET
••••••••
Selection deleted
import aiohttp
import logging
from typing import Dict
import tweepy
import json
import os

logger = logging.getLogger('CryptoBot')

symbol_map = {
    "ripple": "XRP",
    "hedera-hashgraph": "HBAR",
    "stellar": "XLM",
    "xdce-crowd-sale": "XDC",
    "sui": "SUI",
    "ondo-finance": "ONDO",
    "algorand": "ALGO",
    "casper-network": "CSPR"
}

SOCIAL_METRICS_CACHE_FILE = "social_metrics_cache.json"

def load_social_metrics_cache() -> Dict[str, Dict[str, str]]:
    """Load cached social metrics from a file."""
    if os.path.exists(SOCIAL_METRICS_CACHE_FILE):
        with open(SOCIAL_METRICS_CACHE_FILE, 'r') as f:
            return json.load(f)
    return {}

async def fetch_social_metrics(coin_id: str, session: aiohttp.ClientSession) -> Dict[str, str]:
    """Fetch social metrics (mentions) using the X API."""
    cache = load_social_metrics_cache()
    if coin_id in cache:
        logger.debug(f"Using cached social metrics for {coin_id}: {cache[coin_id]}")
        return cache[coin_id]

    hashtag = f"#{symbol_map.get(coin_id, coin_id.split('-')[0].upper())}"

    bearer_token = os.getenv("BEARER_TOKEN")
    if not bearer_token:
        logger.warning(f"X API credentials not configured for {coin_id}. Using fallback social metrics.")
        result = {"mentions": 0, "sentiment": "N/A"}
        cache[coin_id] = result
        save_social_metrics_cache(cache)
        return result

    try:
        client = tweepy.Client(bearer_token=bearer_token)
        query = f"{hashtag} -is:retweet lang:en"
        tweets = client.search_recent_tweets(query=query, max_results=100)
        mentions = len(tweets.data) if tweets.data else 0
        sentiment = "Neutral"  # Add sentiment analysis logic as needed
        result = {"mentions": mentions, "sentiment": sentiment}
        cache[coin_id] = result
        save_social_metrics_cache(cache)
        return result
    except Exception as e:
        logger.error(f"X API error for {coin_id}: {e}")
        result = {"mentions": 0, "sentiment": "N/A"}
        cache[coin_id] = result
        save_social_metrics_cache(cache)
        return result

def save_social_metrics_cache(cache: Dict[str, Dict[str, str]]):
    """Save social metrics to a cache file."""
    with open(SOCIAL_METRICS_CACHE_FILE, 'w') as f:
        json.dump(cache, f)
